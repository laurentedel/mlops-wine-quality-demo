#     chlorides: numeric
!exit
quit()
# # Load the data
# 
# We need to load data from a file in to a Spark DataFrame.
# Each row is a wine, and each column contains attributes of that wine.
#
#     Fields:
#     fixedAcidity: numeric
#     volatileAcidity: numeric
#     citricAcid: numeric
#     residualSugar: numeric
#     chlorides: numeric
#     freeSulfurDioxide: numeric
#     totalSulfurDioxide: numeric
#     density: numeric
#     pH: numeric
#     sulphates: numeric
#     Alcohol: numeric
#     Quality: discrete
# # Data Wrangling 
# ## 1. Read data ( From Spark )
from pyspark.sql import SparkSession
from pyspark.sql.types import *
spark = SparkSession \
  .builder \
  .appName('wine-quality-analysis') \
  .config("spark.hadoop.fs.s3a.aws.credentials.provider","org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider")\
  .config("spark.hadoop.fs.s3a.impl","org.apache.hadoop.fs.s3a.S3AFileSystem")\
  .config("spark.hadoop.fs.s3a.connection.ssl.enabled","true")\
  .config("spark.hadoop.com.amazonaws.services.s3a.enableV4","true")\
  .config("spark.hadoop.fs.s3a.metadatastore.impl","org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore")\
  .config("spark.yarn.access.hadoopFileSystems","s3a://mlamairesse/wine_dataset/")\
  .config("spark.hadoop.fs.s3a.delegation.token.binding","")\
  .getOrCreate()
### Data does not have schema, so we declare it manually 
schema = StructType([StructField("fixedAcidity", DoubleType(), True),     
  StructField("volatileAcidity", DoubleType(), True),     
  StructField("citricAcid", DoubleType(), True),     
  StructField("residualSugar", DoubleType(), True),     
  StructField("chlorides", DoubleType(), True),     
  StructField("freeSulfurDioxide", DoubleType(), True),     
  StructField("totalSulfurDioxide", DoubleType(), True),     
  StructField("density", DoubleType(), True),     
  StructField("pH", DoubleType(), True),     
  StructField("sulphates", DoubleType(), True),     
  StructField("Alcohol", DoubleType(), True),     
  StructField("Quality", StringType(), True)
])
data_path = "s3a://mlamairesse/wine_dataset/data/"
data_file = "WineNewGBTDataSet.csv"
wine_data_raw = spark.read.csv(data_path+'/'+data_file, schema=schema,sep=';')
wine_data_raw.show(3) 
import s3fs
quit()
exit()
